{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data1=pd.read_csv('/kaggle/input/hackereearth/trainse.csv')\ntest1=pd.read_csv('/kaggle/input/hackereearth/testse.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport nltk\nnltk.download('stopwords')\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\nfrom nltk.stem import WordNetLemmatizer\nwordnet=WordNetLemmatizer()\n# Lancaster Stemmer\nfrom nltk.stem import LancasterStemmer\nls = LancasterStemmer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the TF-IDF model\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntv = TfidfVectorizer()\n#X = cv.fit_transform(corpus).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\n# build BOW features on train reviews\ncv = CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[['sentiment_class', 'original_text']]\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['original_text'][5],data['sentiment_class'][5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1=test[['original_text']]\ntest1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef remove_special_characters(text, remove_digits=False):\n    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n    text = re.sub(pattern, '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(data)):\n    data['original_text'][i]=remove_special_characters(data['original_text'][i], remove_digits=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(test1)):\n    test1['original_text'][i]=remove_special_characters(test1['original_text'][i], remove_digits=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_reviews=test1['original_text'].values\ntrain_reviews=data['original_text'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus1 = []\nfor i in range(0, len(test1)):\n    review = re.sub('[^a-zA-Z]', ' ', test1['original_text'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus1.append(review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = []\nfor i in range(0, len(data)):\n    review = re.sub('[^a-zA-Z]', ' ', data['original_text'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test11 = tv.fit_transform(corpus1).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=tv.fit_transform(corpus).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test11.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test11=np.resize(test11,(1387,12545))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['original_text'].apply(lambda x: x.lower()) #transform text to lowercase\ndata['original_text'] = data['original_text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\ndata['original_text'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test11.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['sentiment_class'].values\n#[print(data['sentiment_class'][i], y[i]) for i in range(0,5)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import contractions\nfrom bs4 import BeautifulSoup\nimport numpy as np\nimport re\nimport tqdm\nimport unicodedata\n\n\ndef strip_html_tags(text):\n  soup = BeautifulSoup(text, \"html.parser\")\n  [s.extract() for s in soup(['iframe', 'script'])]\n  stripped_text = soup.get_text()\n  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n  return stripped_text\n\ndef remove_accented_chars(text):\n  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n  return text\n\ndef pre_process_corpus(docs):\n  norm_docs = []\n  for doc in tqdm.tqdm(docs):\n    doc = strip_html_tags(doc)\n    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n    doc = doc.lower()\n    doc = remove_accented_chars(doc)\n    doc wer case and remove special characters\\whitespaces\n    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n    doc = re.sub(' +', ' ', doc)\n    doc == contractions.fix(doc)\n    # lo doc.strip()  \n    norm_docs.append(doc)\n  \n  return norm_docs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pre_process_corpus1(docs):\n  norm_docs = []\n  for review in tqdm.tqdm(docs):\n    review = re.sub('[^a-zA-Z]', ' ' ,review )\n    review = review.lower()\n    review = review.split()\n    \n    review = [ls.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    norm_docs.append(review)\n  \n  return norm_docs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnorm_train_reviews = pre_process_corpus1(train_reviews)\nnorm_test_reviews = pre_process_corpus1(test_reviews)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\n# build BOW features on train reviews\ncv = CountVectorizer()\ncv_train_features = cv.fit_transform(norm_train_reviews)\n\n\n# build TFIDF features on train reviews\ntv = TfidfVectorizer()\ntv_train_features = tv.fit_transform(norm_train_reviews)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# transform test reviews into features\ncv_test_features = cv.transform(norm_test_reviews)\ntv_test_features = tv.transform(norm_test_reviews)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\nprint('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(cv_train_features, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nada=AdaBoostClassifier(MultinomialNB())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression model on BOW features\nfrom sklearn.linear_model import LogisticRegression\n\n# instantiate model\nlr = LogisticRegression(penalty='l2', max_iter=500, C=1, solver='lbfgs', random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm=SVC()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost\nxgb=xgboost.XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel1 = MultinomialNB().fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"help(MultinomialNB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2=xgb.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nepochs = 8\n\nmodel.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model1.predict(cv_test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape[1]-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model1.predict(test11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model1.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nac=accuracy_score(y_test,y_pred)\nac","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test11.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l1=[]\nfor i, prediction in enumerate(predictions):\n    if np.argmax(prediction)==2:\n        l1.append(1)\n    elif np.argmax(prediction)==1:\n        l1.append(-1)\n    else:\n        l1.append(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=pd.DataFrame(predictions,columns=['sentiment_class'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(result.sentiment_class,return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id1=test[['id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm=pd.concat([id1,result],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm.to_csv('/kaggle/working/hacker2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}